version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: booner-ollama-llm
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

  booner-api:
    env_file:
      - .env
    build:
      context: .
      dockerfile: Dockerfile
    container_name: booner-ollama-api
    ports:
      - "8000:8000"
    volumes:
      - .:/app
      - chroma-data:/app/chroma_db
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_LLM_MODEL=${OLLAMA_LLM_MODEL:-mixtral:latest}
      - OLLAMA_EMBED_MODEL=${OLLAMA_EMBED_MODEL:-mxbai-embed-large}
      - VECTOR_DB_DIR=/app/chroma_db
      - OPNSENSE_API_URL=${OPNSENSE_API_URL}
      - OPNSENSE_API_KEY=${OPNSENSE_API_KEY}
      - OPNSENSE_API_SECRET=${OPNSENSE_API_SECRET}
      - MCP_URL=${MCP_URL}
      - MCP_API_KEY=${MCP_API_KEY}
      - DEBUG=${DEBUG:-True}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      - ollama
    restart: unless-stopped

volumes:
  ollama-data:
    name: booner-ollama-data
  chroma-data:
    name: booner-chroma-data
